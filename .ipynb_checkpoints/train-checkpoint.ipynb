{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "import wfdb\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Merge\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "# Hyper-parameters\n",
    "sequence_length = 240\n",
    "epochs = int(input('Enter Number of Epochs (or enter default 1000): '))\n",
    "FS = 100.0\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "def z_norm(result):\n",
    "    result_mean = np.mean(result)\n",
    "    result_std = np.std(result)\n",
    "    result = (result - result_mean) / result_std\n",
    "    return result\n",
    "\n",
    "def split_data(X):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    for index in range(len(X)):\n",
    "        X1.append([X[index][0], X[index][1]])\n",
    "        X2.append([X[index][2], X[index][3]])\n",
    "\n",
    "    return np.array(X1).astype('float64'), np.array(X2).astype('float64')\n",
    "\n",
    "def get_data():\n",
    "    X_train = np.load('train_input.npy', allow_pickle=True)\n",
    "    y_train = np.load('train_label.npy', allow_pickle=True)\n",
    "\n",
    "    X_test = np.load('test_input.npy', allow_pickle=True)\n",
    "    y_test = np.load('test_label.npy', allow_pickle=True)\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    '''\n",
    "    X_train = X_train[:, 0, :]\n",
    "    X_test = X_test[:, 0, :]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    '''\n",
    "    X_train1, X_train2 = split_data(X_train)\n",
    "    X_test1, X_test2 = split_data(X_test)\n",
    "\n",
    "    X_train1 = np.transpose(X_train1, (0, 2, 1))\n",
    "    #X_train2 = np.reshape(X_train2, (X_train2.shape[0], X_train2.shape[1], 1))\n",
    "    X_test1 = np.transpose(X_test1, (0, 2, 1))\n",
    "    #X_test2 = np.reshape(X_test2, (X_test2.shape[0], X_test2.shape[1], 1))\n",
    "\n",
    "    return X_train1, X_train2, y_train, X_test1, X_test2, y_test\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model1 = Sequential()\n",
    "    layers = {'input': 2, 'hidden1': 256, 'hidden2': 256, 'hidden3': 256, 'output': 1}\n",
    "    model1.add(LSTM(layers['hidden1'],\n",
    "                   input_shape= (sequence_length, layers['input']),\n",
    "                    recurrent_dropout=0.5,\n",
    "                   return_sequences=True))\n",
    "\n",
    "    model1.add(LSTM(\n",
    "            layers['hidden2'],\n",
    "            recurrent_dropout=0.5,\n",
    "            return_sequences=True))\n",
    "\n",
    "    model1.add(LSTM(\n",
    "            layers['hidden3'],\n",
    "            recurrent_dropout=0.5,\n",
    "            return_sequences=False))\n",
    "\n",
    "    model1.summary()\n",
    "\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(32, input_dim=2))\n",
    "\n",
    "    model2.summary()\n",
    "\n",
    "    merged = Merge([model1, model2], mode='concat')\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(merged)\n",
    "    model.add(Dense(8))\n",
    "    model.add(Dense(\n",
    "        output_dim=layers['output'],\n",
    "        kernel_initializer='normal'))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "                  metrics = ['accuracy'])\n",
    "    print (\"Compilation Time : \", time.time() - start)\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_network(model=None, data=None):\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    print ('\\nData Loaded. Compiling...\\n')\n",
    "    print('Loading data... ')\n",
    "    X_train1, X_train2, y_train, X_test1, X_test2, y_test = get_data()\n",
    "\n",
    "    class_w = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(y_train),\n",
    "                                                     y_train)\n",
    "\n",
    "    print (class_w)\n",
    "\n",
    "    if model is None:\n",
    "        model = build_model()\n",
    "\n",
    "    try:\n",
    "        print(\"Training\")\n",
    "        history = LossHistory()\n",
    "        history.init()\n",
    "\n",
    "        model.fit([X_train1, X_train2], y_train, epochs=epochs, batch_size=256, callbacks=[history], validation_split=0.1, class_weight=class_w)\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        '''\n",
    "        plt.plot(history.losses)\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train'], loc='upper left')\n",
    "        plt.show()\n",
    "        '''\n",
    "        # Evaluate Model\n",
    "        y_pred = model.predict([X_test1, X_test2])\n",
    "        scores = model.evaluate([X_test1, X_test2], y_test)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"prediction exception\")\n",
    "        print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "        return model\n",
    "\n",
    "\n",
    "    print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    return model\n",
    "\n",
    "run_network()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
